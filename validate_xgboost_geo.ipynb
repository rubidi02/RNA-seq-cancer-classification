{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5448272d",
   "metadata": {},
   "source": [
    "# **GEO exploratory dataset analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dbdfab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/610z7jsx3nqcx8spxps6wzrr0000gn/T/ipykernel_9088/1197402071.py:13: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  annot = pd.read_csv('../data/data-geo-2/colon/Human.GRCh38.p13.annot.tsv', delimiter='\\t', index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_geo loaded!\n",
      "Index([100287102,    653635, 102466751, 107985730, 100302278,    645520,\n",
      "           79501, 100996442,    729737, 102725121,\n",
      "       ...\n",
      "            4538,      4564,      4575,      4568,      4540,      4541,\n",
      "            4556,      4519,      4576,      4571],\n",
      "      dtype='int64', name='GeneID', length=39376)\n",
      "Total geo columns: 39376\n",
      "Unique geo columns: 39376\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from mygene import MyGeneInfo\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pyensembl import EnsemblRelease\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Specify the path to the parent directory containing the folders to iterate through\n",
    "data_geo_file_path = \"data_geo.pkl\"\n",
    "\n",
    "# load annotation file\n",
    "annot = pd.read_csv('../data/data-geo-2/colon/Human.GRCh38.p13.annot.tsv', delimiter='\\t', index_col=0)\n",
    "\n",
    "#load data from GEO\n",
    "data_geo = pd.read_csv('../data/data-geo-2/colon/GSE180440_norm_counts_TPM_GRCh38.p13_NCBI.tsv', delimiter='\\t', index_col=0)\n",
    "\n",
    "# Extract the second column from annot\n",
    "second_column = annot.iloc[:, 1]\n",
    "\n",
    "# Replace the first column of data_geo with the second column of annot\n",
    "data_geo.iloc[:, 0] = second_column\n",
    "\n",
    "data_geo = data_geo.transpose()\n",
    "\n",
    "# Select the first 1000 columns\n",
    "#data_geo = data_geo.iloc[:, :1000]\n",
    "\n",
    "print(\"data_geo loaded!\")\n",
    "print(data_geo.columns)\n",
    "print(f'Total geo columns: {len(data_geo.columns)}')\n",
    "print(f'Unique geo columns: {len(set(data_geo.columns))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "637b3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneID      DDX11L1  WASH7P  MIR6859-1  MIR1302-2HG  MIR1302-2  FAM138A   \n",
      "GSM3384758  0.09273   2.988     2.2530      0.04746     0.0000  0.02259  \\\n",
      "GSM3384759  1.29000   9.081    21.7000      0.76170     1.7820  0.94290   \n",
      "GSM3384760  0.05769   6.088     5.1390      0.00000     0.0000  0.00000   \n",
      "GSM3384761  1.79300  13.730     4.8880      0.05616     0.2190  0.00000   \n",
      "GSM3384762  0.17120   5.008     5.5440      0.00000     0.0000  0.08341   \n",
      "...             ...     ...        ...          ...        ...      ...   \n",
      "GSM3384851  0.10030   2.450     1.3930      0.04401     0.0000  0.00000   \n",
      "GSM3384852  0.06520   3.973     3.5640      0.00000     0.0000  0.02383   \n",
      "GSM3384853  0.08953   3.846     6.1630      0.00000     0.0000  0.00000   \n",
      "GSM3384854  0.07361   2.997     0.3576      0.00000     0.0000  0.00000   \n",
      "GSM3384855  0.77390  11.750     8.8000      0.10110     0.1971  0.00000   \n",
      "\n",
      "GeneID        OR4F5  LOC100996442  LOC729737  DDX11L17  ...     ND4     TRNH   \n",
      "GSM3384758  0.00000       0.27650    0.11190   0.11120  ...   114.1   10.730  \\\n",
      "GSM3384759  0.44640       0.68670    1.49700   1.98900  ...  1032.0  877.800   \n",
      "GSM3384760  0.03461       0.70760    0.92280   0.09885  ...   822.8   21.640   \n",
      "GSM3384761  0.00000       0.53100    0.32570   3.83600  ...   760.8   17.520   \n",
      "GSM3384762  0.10270       0.44290    0.84370   0.35190  ...  1047.0  278.600   \n",
      "...             ...           ...        ...       ...  ...     ...      ...   \n",
      "GSM3384851  0.00000       0.06774    0.05191   0.13260  ...   140.1  660.600   \n",
      "GSM3384852  0.00000       0.17610    0.06395   0.11730  ...   185.8    6.634   \n",
      "GSM3384853  0.00000       0.12590    0.04503   0.27610  ...   266.4   12.150   \n",
      "GSM3384854  0.00000       0.11430    0.01333   0.07567  ...   134.4    8.106   \n",
      "GSM3384855  0.00000       0.23340    0.55650   0.79550  ...   127.5   13.010   \n",
      "\n",
      "GeneID         TRNS2    TRNL2     ND5      ND6     TRNE   CYTB    TRNT    TRNP  \n",
      "GSM3384758    10.820   15.460   73.38    38.76    73.26  158.6   95.16   360.4  \n",
      "GSM3384759  1160.000  914.300  871.40  1237.00  1105.00  961.5  465.70  1040.0  \n",
      "GSM3384760     7.539   16.560  428.50   284.50   477.00  698.3  218.50   435.0  \n",
      "GSM3384761    14.340   16.170  540.60   385.90   357.80  890.6   87.90   640.8  \n",
      "GSM3384762   447.300  382.300  615.10   387.60   707.50  568.8  149.90   614.0  \n",
      "...              ...      ...     ...      ...      ...    ...     ...     ...  \n",
      "GSM3384851     8.428    6.670   76.11    38.11    52.85  281.6   19.37   820.8  \n",
      "GSM3384852     9.128    9.102   80.58    47.55    43.32  232.0   37.13   575.8  \n",
      "GSM3384853    13.370   11.110  103.20   146.30    94.32  440.9   43.33   188.5  \n",
      "GSM3384854     8.656   10.280   64.52    32.15    54.98  203.6   24.69   135.9  \n",
      "GSM3384855    13.830   10.340   62.33    38.60    50.85  215.4   52.75   118.4  \n",
      "\n",
      "[96 rows x 39376 columns]\n",
      "Done. Gene ID replaced by Gene name in data_geo!\n"
     ]
    }
   ],
   "source": [
    "# verify if the all_data_file_path exist or not\n",
    "if not os.path.exists(data_geo_file_path):\n",
    "\n",
    "    # Converting gene id to gene name\n",
    "    def convert_gene_id_to_name(gene_id):\n",
    "        mg = MyGeneInfo()\n",
    "        gene_info = mg.getgene(gene_id)\n",
    "\n",
    "        if gene_info is not None and 'symbol' in gene_info:\n",
    "            gene_name = gene_info['symbol']\n",
    "        else:\n",
    "            gene_name = None\n",
    "\n",
    "        return gene_name\n",
    "\n",
    "    # Function to process a column and return the gene name\n",
    "    def process_column(col):\n",
    "        gene_name = convert_gene_id_to_name(col)\n",
    "        return gene_name\n",
    "\n",
    "    # Use ThreadPoolExecutor to parallelize column processing\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Create a list of column names\n",
    "        columns_list = data_geo.columns.tolist()\n",
    "\n",
    "        # Process columns in parallel\n",
    "        results = executor.map(process_column, columns_list)\n",
    "\n",
    "        # Replace column names with gene names in the DataFrame\n",
    "        for col, gene_name in zip(columns_list, results):\n",
    "            data_geo.rename(columns={col: gene_name}, inplace=True)\n",
    "\n",
    "    print(data_geo)\n",
    "    print(\"Done. Gene ID replaced by Gene name in data_geo!\")\n",
    "    \n",
    "    # store the count matrices and labels into pickle files\n",
    "    with open(data_geo_file_path, 'wb') as f:\n",
    "        pickle.dump(data_geo, f)\n",
    "\n",
    "else: # .pkl file exists, load everything from it to skip processing\n",
    "\n",
    "    with open(data_geo_file_path, 'rb') as f:\n",
    "        data_geo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6a33d",
   "metadata": {},
   "source": [
    "No duplicated columns, no need to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ebc9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the list of genes from tcga\n",
    "\n",
    "all_data_columns_file_path = './all_data_columns.pkl'\n",
    "\n",
    "with open(all_data_columns_file_path, 'rb') as all_data_columns_pckl:\n",
    "    all_data_columns = pickle.load(all_data_columns_pckl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7b922c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 0)\n",
      "(150, 59427)\n"
     ]
    }
   ],
   "source": [
    "# Delete all columns from data_geo dataframe that are not present in all_data_columns list\n",
    "columns_to_drop = [col for col in data_geo.columns if col not in all_data_columns]\n",
    "data_geo_filtered = data_geo.drop(columns=columns_to_drop)\n",
    "print(data_geo_filtered.shape)\n",
    "      \n",
    "# For each column name in all_data_columns list add a column of zeros to data_geo_filtered dataframe \n",
    "# if the column with that name does not exist, otherwise ignore it\n",
    "\n",
    "# Create a DataFrame with zeros for missing columns\n",
    "zeros_df = pd.DataFrame(0, index=data_geo_filtered.index, columns=all_data_columns)\n",
    "\n",
    "# Concatenate data_geo_filtered and zeros_df\n",
    "data_geo_filtered = pd.concat([data_geo_filtered, zeros_df], axis=1)\n",
    "\n",
    "# Remove duplicate columns\n",
    "data_geo_filtered = data_geo_filtered.loc[:, ~data_geo_filtered.columns.duplicated()]\n",
    "\n",
    "\n",
    "# Construct validation dataset with proper column ordering defined in all_data_columns\n",
    "data_geo_test = data_geo_filtered[all_data_columns]\n",
    "print(data_geo_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba21b5",
   "metadata": {},
   "source": [
    "To do: compute statistics about column merging and deletion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d1353eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC004492.1    0\n",
      "MIR4639       0\n",
      "RN7SL28P      0\n",
      "TRBV7-4       0\n",
      "ADARB2-AS1    0\n",
      "             ..\n",
      "DHRS11        0\n",
      "IRF3          0\n",
      "FCF1P5        0\n",
      "AC099811.4    0\n",
      "DPP8          0\n",
      "Length: 59427, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# confirming that columns contain none zero values, as expected\n",
    "print(data_geo_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e343cdd",
   "metadata": {},
   "source": [
    "# Validata data geo on trained tcga classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8cc1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the xgboost model\n",
    "model_file_name = 'cancer_xgboost.model'\n",
    "\n",
    "with open(model_file_name, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a868527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load label encoder from pickle file\n",
    "encoder_file = './encoder.pkl'\n",
    "\n",
    "with open(encoder_file, 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "    \n",
    "# create dataframe for storing labels\n",
    "\n",
    "all_labels = ['colon'] * data_geo_test.shape[0]\n",
    "print(len(all_labels))\n",
    "\n",
    "# encoding the test data with the same label encoder used in training\n",
    "all_labels_encoded = label_encoder.transform(all_labels)\n",
    "print(all_labels_encoded)\n",
    "\n",
    "#Sorting the data_geo_test columns\n",
    "\n",
    "data_geo_test = data_geo_test[sorted(data_geo_test.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a819a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying accuracy...\n",
      "Accuracy of the test: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying accuracy...\")\n",
    "# verify accuracy of the test data\n",
    "pred_test = model.predict(data_geo_test)\n",
    "\n",
    "accuracy = sum(pred_test == all_labels_encoded) / float(len(pred_test))\n",
    "\n",
    "print(\"Accuracy of the test: %.4f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aea2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
